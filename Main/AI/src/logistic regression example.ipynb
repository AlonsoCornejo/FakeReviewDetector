{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"logistic regression example.ipynb","provenance":[{"file_id":"1__jQLebpmSOtVcGfakiiXygHVKEECFSE","timestamp":1594939356069}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"cghK2gv1ysE1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":104},"executionInfo":{"status":"ok","timestamp":1595695936770,"user_tz":240,"elapsed":389,"user":{"displayName":"Jack Curtis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWhFjCbNZD51kkXjy5Tu-HjfmfJ_W5FbUoM5o6=s64","userId":"03893034601236709736"}},"outputId":"b7f8354b-f337-460b-be65-31cfcc9292f2"},"source":["import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","\n","# each row of X is the feature vector of an account/review\n","X = np.array([[1,2,3,4,5,6],    # user_id = '6785'\n","     [6,5,4,3,2,1],\n","     [2,1,3,4,5,6],\n","     [2,1,3,4,5,6]])\n","\n","train_X = X[:2, :]\n","test_X = X[2:,:]\n","\n","# each row of y is a the label of the corresponding account/review (0-non-spam, 1-spam).\n","y = np.array([[1],\n","     [0],\n","     [1],\n","     [0]]\n",")\n","train_y = y[:2, :]\n","test_y = y[2:,:]\n","\n","clf = LogisticRegression(random_state=0).fit(train_X, train_y)\n","\n","predicted_prior =clf.predict_proba(test_X)\n","\n","print(predicted_prior)\n","\n","# mapping from row number of predicted_priors to user_id\n","\n","# create a dictionary containing user_id as keys and Pr (spam | user_id) as value\n","# Pr (spam | user_id): second column of predicted_priors \n","# pickle.dump(dictionary to a new user prior pickle file)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[0.0831686 0.9168314]\n"," [0.0831686 0.9168314]]\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6FHgoxbJHG33","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"-oohsF9Cuhwt","colab_type":"text"},"source":["# Importing Pickle Files and loading Features\n","\n","In order to import the pickle files, i had to mount it to my whole google drive, so please only use the AI forlder if you need anything"]},{"cell_type":"code","metadata":{"id":"YuguHUqlt_Ml","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"error","timestamp":1595700364796,"user_tz":240,"elapsed":399,"user":{"displayName":"Jack Curtis","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgWhFjCbNZD51kkXjy5Tu-HjfmfJ_W5FbUoM5o6=s64","userId":"03893034601236709736"}},"outputId":"da1e313b-885d-4133-b36a-93fa33c4077e"},"source":["import pickle\n","\n","prefix = '/content/drive/My Drive/D4I 2020 Summer/AI/src/'\n","\n","user_feature_filename = prefix + 'UserFeatures.pickle'\n","prod_feature_filename = prefix + 'ProdFeatures.pickle'\n","review_feature_filename = prefix + 'ReviewFeatures.pickle'\n","\n","with open(user_feature_filename, 'rb') as f:\n","\t\tuser_features = pickle.load(f)\n","\n","with open(prod_feature_filename, 'rb') as f:\n","\t\tprod_features = pickle.load(f)\n","\t\n","with open(review_feature_filename, 'rb') as f:\n","\t\treview_features = pickle.load(f)\n","\t\n","# examples of using the dictionary with the pickle files\n","\n","print(user_features.get('11111'))\n","\n","x = user_features.get('11111')\n","print(x['PR'])\n","\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-76288df0a1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mreview_feature_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ReviewFeatures.pickle'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_feature_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                 \u001b[0muser_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/D4I 2020 Summer/AI/src/UserFeatures.pickle'"]}]},{"cell_type":"code","metadata":{"id":"OQHPKvfyxFRx","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1hEvXXvUjr7k","colab_type":"text"},"source":["New Training and Test Data Split 7/26"]},{"cell_type":"code","metadata":{"id":"KWs2zWKPI93Z","colab_type":"code","colab":{}},"source":["# Define new dictionaries to hold training  data\n","\t\tuser_train_X = [] #initialized to arrays\n","\t\tuser_train_Y = []\n","\t\tuser_test_X = []\n","\t\tuser_test_Y = []\n","\t\t\n","\t\treview_train_X = []\n","\t\treview_train_Y = []\n","\t\treview_test_X = []\n","\t\treview_test_Y = []\n","\t\t\n","\t\t\n","\t\tuser_feature_names = {'MNR': 0.05555555555555555, 'PR': 1.0, 'NR': 0.0, 'avgRD': 0.36013986013986, 'BST': 1.0, 'ERD': 0.0, 'ETG': 0}\n","\t\treview_feature_names = {'RD': 2.0, 'EXT': 1, 'DEV': 0, 'ETF': 0, 'ISR': 1}\n","\n","\t\t# Get (spammers) ammount of spam and non spam users for the training data\n","\t\tfor i in range(spammers):\n","\t\t\tk = user_spam_idx[i]\n","\t\t\t# user_train_X[k] = user_X.pop(k)\n","\t\t\tuser_feature_vector = [user_X[k][name] for name in user_feature_names.keys()]\n","\t\t\tuser_train_X.append(user_feature_vector)\n","\t\t\t# user_train_Y[k] = user_Y.pop(k)\n","\t\t\tuser_train_Y.append(user_Y[k])\n","\t\t\n","\t\t#for real users\n","\t\tfor i in range(spammers):\n","\t\t\tk = user_real_idx[i]\n","\t\t\tuser_feature_vector = [user_X[k][name] for name in user_feature_names.keys()]\n","\t\t\tuser_train_X.append(user_feature_vector)\n","\t\t\t# user_train_X[k] = user_X.pop(k)\n","\t\t\tuser_train_Y.append(user_Y[k])\n","\t\t\t# user_train_Y[k] = user_Y.pop(k)\n","\t\t\n","\t\t#populate test cases\n","\t\tfor k in user_features.keys():\n","\t\t\tif k not in user_spam_idx and k not in user_real_idx:\n","\t\t\t\tuser_feature_vector = [user_X[k][name] for name in user_feature_names.keys()]\n","\t\t\t\tuser_test_X.append(user_feature_vector)\n","\t\t\t\tuser_test_Y.append(user_Y[k])\n","\t\t\n","\t\tuser_test_X = np.array(user_test_X)\n","\t\tuser_test_Y = np.array(user_test_Y)\n","\t\tuser_train_X = np.array(user_train_X)\n","\t\tuser_train_Y = np.array(user_train_Y)\n","\t\t# print(user_train_X.shape)\n","\t\t# print(user_train_Y.shape)\n","\n","\t\t# Get (spams) ammount of spam and non spam reviews for the training data\n","\t\t#for fake reviews\n","\t\tfor i in range(spams):\n","\t\t\tuk = review_spam_idx1[i]\n","\t\t\tpk =  review_spam_idx2[i]\n","\t\t\treview_feature_vector = [review_X[(uk, pk)][name] for name in review_feature_names.keys()]\n","\t\t\t#review_train_X[uk, pk] = review_X.pop(uk, pk) #Read Only structure, not necessary to modify\n","\t\t\treview_train_X.append(review_feature_vector)\n","\t\t\t#review_train_Y[uk, pk] = review_Y.pop(uk, pk)\n","\t\t\treview_train_Y.append(review_Y[(uk, pk)])\n","\t\t\n","\t\t#for real reviews\n","\t\tfor i in range(spams):\n","\t\t\tuk = review_real_idx1[i]\n","\t\t\tpk =  review_real_idx2[i]\n","\t\t\treview_feature_vector = [review_X[(uk, pk)][name] for name in review_feature_names.keys()]\n","\t\t\treview_train_X.append(review_feature_vector)\n","\t\t\treview_train_Y.append(review_Y[(uk, pk)])\n","\n","\t\t#populate test cases\n","\t\tfor (uk, pk) in review_features.keys():\n","\t\t\tif uk not in review_spam_idx1 and uk not in review_real_idx1 and pk not in review_spam_idx2 and pk not in review_real_idx2:\n","\t\t\t\treview_feature_vector = [review_X[(uk, pk)][name] for name in review_feature_names.keys()]\n","\t\t\t\treview_test_X.append(review_feature_vector)\n","\t\t\t\treview_test_Y.append(review_Y[(uk, pk)])\n","\n","\t\treview_test_X = np.array(review_test_X)\n","\t\treview_test_Y = np.array(review_test_Y)\n","\t\treview_train_X = np.array(review_train_X)\n","\t\treview_train_Y = np.array(review_train_Y)\n","\n","\t\tprint('Data divided into train and test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Plyyr1yHI4je","colab_type":"text"},"source":["Diverse Reviews"]},{"cell_type":"code","metadata":{"id":"QKDPOspiIujV","colab_type":"code","colab":{}},"source":["# Get reviews with more diverse numbers\n","\t# import user and review features\n","\t\n","\tdiverse_reviews = {}\n","\tdiverse_users = {}\n","\n","\tsize = 0\n","\tg = 0\n","\twhile size < 20:\n","\t\tmnr_dict = {}\n","\n","\t\tfor k, v in user_features.items():\n","\t\t\t\n","\t\t\tg += 1\n","\n","\t\t\t#print('Entered for loop')\n","\t\t\tmnr = v.get('MNR')\n","\t\t\t\n","\t\t\tif mnr not in mnr_dict.keys():\n","\t\t\t\t#print(str(mnr))\n","\t\t\t\t#print(mnr_dict.keys())\n","\t\t\t\t# print('New mnr value')\n","\t\t\t\tif k not in diverse_users.keys():\n","\t\t\t\t\tmnr_dict[mnr] = 1\n","\t\t\t\t\t# print('New user')\n","\t\t\t\t\tdiverse_users[k] = v\n","\t\t\t\t\tsize += 1 \n","\t\t\t\t\tprint('Size: ' + str(size))\n","\t\t\tif size == 20:\n","\t\t\t\tbreak\n","\n","\ti = 0\n","\tfor k, v in review_features.items():\n","\n","\t\tuser = k[0]\n","\n","\t\tif user in diverse_users.keys():\n","\t\t\tdiverse_reviews[k] = v\n","\n","\n","\t\t\n","\t# review key will relate the review to the labeled review in review_Y \n","\t# use that to pick diverse reviews\n","\n","\n","\tprint('\\nDiverse Reviews')\n","\tfor k, v in diverse_reviews.items():\n","\t\tprint(str(k) + ' ' + str(v))\n","\n","\t# print('\\nDiverse users')\n","\t# for k, v in diverse_users.items():\n","\t# \tprint(str(k) + ' ' + str(v))\n","\n","\n","\t# get 20 reviews\n","\t# diverse mnr values\n","\t# 10 spam 10 not spam"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pkafHjgDXXsk","colab_type":"text"},"source":["Logistic Regression and Weight Extraction Code"]},{"cell_type":"code","metadata":{"id":"bm-JY4qAXayf","colab_type":"code","colab":{}},"source":["\tu_clf = LogisticRegression(random_state=0).fit(user_train_X, user_train_Y)\n","\tu_predicted_prior = u_clf.predict_proba(user_test_X) \n","\tprint(\"\\nUser Probabilities:\")\n","\tprint(u_predicted_prior)\n","\n","\t#Running LogReg on user/review feature sets\n","\tr_clf = LogisticRegression(random_state=0).fit(review_train_X, review_train_Y)\n","\tr_predicted_prior = r_clf.predict_proba(review_test_X) \n","\tprint(\"\\nReview Probabilities:\")\n","\tprint(r_predicted_prior)\t\n","\n","\tr_feature_weights = r_clf.coef_[0]\n","\tu_feature_weights = u_clf.coef_[0]\n","\t\n","\tr_Weights = {\"RD\": r_feature_weights[0], \"EXT\": r_feature_weights[1], \"DEV\": r_feature_weights[2], \"ETF\": r_feature_weights[3], \"ISR\": r_feature_weights[4]}\n","\tu_Weights = {\"MNR\": u_feature_weights[0], \"PR\": u_feature_weights[1], \"NR\": u_feature_weights[2], \"avgRD\": u_feature_weights[3], \"BST\": u_feature_weights[4], \"ERD\": u_feature_weights[5], \"ETG\": u_feature_weights[6]}\n","\tprint(\"\\nUser Feature Weights\")\n","\tprint(u_Weights)\n","\tprint(\"\\nReview Feature Weights\")\n","\tprint(r_Weights)"],"execution_count":null,"outputs":[]}]}