{"cells":[{"cell_type":"markdown","source":["## Subteam 1: Creating a dictionary out of the review text file."],"metadata":{"id":"9XrDvOP2R3fk"}},{"cell_type":"markdown","source":["Here is Subteam 1's results. In our portion of the project, we are making a dictionary out of the provided text file and in combination with LIWC's dictionary, we will use this to create NLP models later on.\n"],"metadata":{"id":"8DlSj8XyRoVr"}},{"cell_type":"markdown","source":["Here we just mount this google drive to work with the files in the folder"],"metadata":{"id":"3_rq6CUKRy4e"}},{"cell_type":"code","source":["from google.colab import drive \n","drive.mount('/content/gdrive')\n","import numpy as np"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPw1CUhnpsBn","executionInfo":{"status":"ok","timestamp":1649713992265,"user_tz":240,"elapsed":1445,"user":{"displayName":"Kamilla Muminova","userId":"04376261050601407819"}},"outputId":"5414778a-1925-4eee-84c9-20f861dd0f35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["First, we will need to make a pseudo LIWC dictionary until we can have access to the real one"],"metadata":{"id":"mRBq9frUR0iC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"g0UGj0iskosj"},"outputs":[],"source":["\n","#Our fake LIWC dictionary that we will replace later with a real one. Changing this will change everything, making our dictionary and ndarray bigger.\n","LIWC = {'Self': ['I', 'we', 'me', 'my'], 'Dirty':['Disgusting', 'Gross', 'Rats', 'Run Down'],'Blah': ['No', 'crazy', 'aweful']}\n"]},{"cell_type":"markdown","metadata":{"id":"2ZvOWLTRkosm"},"source":["After we have made this function, we will load in our file of reviews that was shared with us."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WD8o0udskosn","executionInfo":{"status":"ok","timestamp":1649713992276,"user_tz":240,"elapsed":57,"user":{"displayName":"Kamilla Muminova","userId":"04376261050601407819"}},"outputId":"17329c26-ed67-48ea-f092-42b2a2bc81d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of reviews in the file:  5854\n"]}],"source":["#read and store the whole file to pass into our func later\n","f = open(\"/content/gdrive/MyDrive/CSE-CSB_Capstone/Subteam-1/output_review_yelpHotelData_NRYRcleaned.txt\",\"r\")\n","f_content = f.read()\n","\n","#an array that will store each of the \\n seperated reviews from the file.\n","reviews=[]\n","\n","#open the file and seperate each review by the \\n char\n","with open(\"/content/gdrive/MyDrive/CSE-CSB_Capstone/Subteam-1/output_review_yelpHotelData_NRYRcleaned.txt\",\"r\",newline=\"\\n\") as file:\n","    count = 0\n","    #for each of the \n","    for review in file:\n","        reviews.append(review.rstrip())\n","print(\"Number of reviews in the file: \",len(reviews))\n","#del review,file\n"]},{"cell_type":"markdown","source":["Then, we will create a function that will take a piece of text, and using our LIWC dictionary, compare words in the text to the categories in the LIWC dict. This function will then return a dictionary of our own that will contain each category and the number of times each category appeared in the text."],"metadata":{"id":"HY78Yj8ASWfs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3H00YOaykosl"},"outputs":[],"source":["#This function takes in a corpus, extracts the words in the categories that are present in the LIWC dictionary from that body of text. Then, it counts the number of occurances \n","#of those words, and returns a dictionary with categories as keys and the number of times each category's words occur as values.\n","def LIWC_feature_extraction(text):\n","    #create a dictionary that will hold our values\n","    feature_dict={}\n","\n","    #for every key in the LIWC, we compare our text to the categories and \n","    #then we increment whenever a word from the key/ value appears in our text\n","    for key in LIWC:\n","      num_occur = 0\n","      for i in LIWC[key]:\n","        num_occur += text.count(i)\n","      feature_dict[key] = num_occur\n","\n","    \n","    return feature_dict"]},{"cell_type":"markdown","source":["Here we demonstrate the LIWC_feature_extraction function"],"metadata":{"id":"EJSXrVvsScvU"}},{"cell_type":"code","source":["#Testing the LIWC_feature_extraction() functionality\n","#if we want all of the words in the file to be analyzed\n","print(LIWC_feature_extraction(f_content))\n","\n","#a specific review in our file to be analyzed\n","print(LIWC_feature_extraction(reviews[4]))\n","\n","#lets store the dictionary that results from the feature extraction in review_dict\n","review_dict = LIWC_feature_extraction(f_content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBuG9KI8G-fe","executionInfo":{"status":"ok","timestamp":1649713992484,"user_tz":240,"elapsed":252,"user":{"displayName":"Kamilla Muminova","userId":"04376261050601407819"}},"outputId":"87e45b29-b280-4803-d836-d52d24d37698"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Self': 76654, 'Dirty': 19, 'Blah': 1566}\n","{'Self': 5, 'Dirty': 0, 'Blah': 0}\n"]}]},{"cell_type":"markdown","source":["After this, we create a function that will convert our dictionary of review into a numpy.ndarray"],"metadata":{"id":"t9fm3Y_LSkL-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JiCtFLokosp"},"outputs":[],"source":["#This function takes in a dictionary, and then returns a 1xn numpy array of the features of the dictionary with the number of occurances of each \n","#key as its elements\n","def dict_to_nparray(dictionary):\n","  #associate each characteristic to a number, and then: [[70484,19]] (1x2 matrix) return matrix will be 5854 elements\n","  vals = np.fromiter(dictionary.values(), dtype=int)\n","    \n","  # reshape the the numpy array to be a 1x(number of keys in dictionary) matrix\n","  vals = vals.reshape(1,len(dictionary))\n","\n","  #return an ndarray that will hold the number of times each characteristic appears for the corpus\n","  return vals\n","\n","\n","\n","\n"]},{"cell_type":"markdown","source":["Now, for each review in the text file, we append to a vector of arrays of feature counts, a 2xn numpy array"],"metadata":{"id":"RE5msJlyTOp6"}},{"cell_type":"code","source":["#create an array to fill with values later that is the size of 1xnumber of features in LIWC size.\n","rfeatures = LIWC_feature_extraction(reviews[0])\n","all_reviews_array = dict_to_nparray(rfeatures)\n","\n","#for each review in the list of reviews, extract the features from it, count the number of occurances of each feature, \n","#store in a numpy array, and append it to a 2xn numpy vector of all the feature counts of each review. \n","for review in reviews:\n","  if review == reviews[0]:\n","    continue\n","  else:\n","    rfeatures = LIWC_feature_extraction(review)\n","    x = dict_to_nparray(rfeatures)\n","    all_reviews_array = np.append(all_reviews_array,x,axis=0)"],"metadata":{"id":"s3R8jMw2TOF7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here we test randomly to make sure everything is in working order"],"metadata":{"id":"-hS-D71jTcfC"}},{"cell_type":"code","source":["\n","#testing\n","print(\"Len of the reviews numpy 2xn array:\")\n","print(len(all_reviews_array))\n","print()\n","print(\"Review 1 feature counts: \")\n","print(all_reviews_array[0])\n","print(\"Comparing against feature extraction function's results: \")\n","print(LIWC_feature_extraction(reviews[0]))\n","print()\n","print(\"Review 2 feature counts: \")\n","print(all_reviews_array[1])\n","print(\"Comparing against feature extraction function's results: \")\n","print(LIWC_feature_extraction(reviews[1]))\n","print()\n","print(\"Review 6 feature counts: \")\n","print(all_reviews_array[5])\n","print(\"Comparing against feature extraction function's results: \")\n","print(LIWC_feature_extraction(reviews[5]))\n","print()\n","print(\"Review 5854 feature counts: \")\n","print(all_reviews_array[5852])\n","print(\"Comparing against feature extraction function's results: \")\n","print(LIWC_feature_extraction(reviews[5852]))\n","\n","#I would like to create a way to go through each review and "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UaHFSxZgQmfe","executionInfo":{"status":"ok","timestamp":1649713992790,"user_tz":240,"elapsed":326,"user":{"displayName":"Kamilla Muminova","userId":"04376261050601407819"}},"outputId":"8727dbc6-870d-4b8d-acdd-bbddbf40e287"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Len of the reviews numpy 2xn array:\n","5854\n","\n","Review 1 feature counts: \n","[21  0  0]\n","Comparing against feature extraction function's results: \n","{'Self': 21, 'Dirty': 0, 'Blah': 0}\n","\n","Review 2 feature counts: \n","[1 0 0]\n","Comparing against feature extraction function's results: \n","{'Self': 1, 'Dirty': 0, 'Blah': 0}\n","\n","Review 6 feature counts: \n","[3 1 1]\n","Comparing against feature extraction function's results: \n","{'Self': 3, 'Dirty': 1, 'Blah': 1}\n","\n","Review 5854 feature counts: \n","[17  0  0]\n","Comparing against feature extraction function's results: \n","{'Self': 17, 'Dirty': 0, 'Blah': 0}\n"]}]},{"cell_type":"code","source":["def key_category(nparray):\n","  max_val_index = np.argmax(nparray) #max of the array to use as an index for our key\n","  keys_list = list(LIWC)\n","  dict_cat = keys_list[max_val_index]\n","  return dict_cat\n","\n","\n","#testing this function\n","print(\"Most frequent category of review 1: \")\n","print(key_category(all_reviews_array[0]))\n","print()\n","print(\"Most frequent category of review 6: \")\n","print(key_category(all_reviews_array[5]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0FP57aElM17","executionInfo":{"status":"ok","timestamp":1649713992794,"user_tz":240,"elapsed":60,"user":{"displayName":"Kamilla Muminova","userId":"04376261050601407819"}},"outputId":"aaef5c99-f4bd-4242-b180-62240de43679"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Most frequent category of review 1: \n","Self\n","\n","Most frequent category of review 6: \n","Self\n"]}]},{"cell_type":"markdown","source":["SVM:"],"metadata":{"id":"8oGlIauk29MI"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import preprocessing\n","\n","#read in data\n","#LIWC_result=pd.read_csv(\"LIWC-outputOnContentsAndNY.csv\");\n","\n","\n","#create the classifier df\n","df_X=LIWC_result.drop([\"realOrFake\",\"Unnamed: 0\",\"content\",\"unknown1\",\"unknown2\",\"unknown3\",\"Segment\",\"dates\",\"reviewID\",\"reviewerID\",\"productID\"],axis=\"columns\")\n","\n","#create the target df\n","df_Y=LIWC_result.realOrFake\n","\n","\n","#split into training and testing sets by a 2:8 ratio \n","Xtr,Xte,Ytr,Yte=train_test_split(df_X,df_Y,test_size=0.2)\n","\n","#parameter range\n","#param_grid = {'C': [ 1, 10], \n","#             'gamma': [1,0.1],\n","#             'kernel': ['rbf']} \n","\n","#search for best parameters\n","#grid = GridSearchCV(model, param_grid, refit = True, cv=15)\n","\n","#prepossess the data, so that grid.fit doesn't run for several hours\n","#Xtr = preprocessing.scale(Xtr) \n","\n","#run this for several minutes\n","#grid_search=grid.fit(Xtr,Ytr)\n","\n","#print(grid_search.best_estimator_)\n","\n","#create model\n","model=svm.SVC(C=1,gamma=1)\n","model.fit(Xtr,Ytr)\n","print(model.score(Xte,Yte))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":247},"id":"4mOeL3lO24Dx","executionInfo":{"status":"error","timestamp":1650573839411,"user_tz":240,"elapsed":1443,"user":{"displayName":"Yifan She","userId":"10901471948661696856"}},"outputId":"bd32fad4-3179-4e6a-d0fb-62ad8b8528c5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3fd015678dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#create the classifier df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdf_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLIWC_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"realOrFake\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Unnamed: 0\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"content\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"unknown1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"unknown2\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"unknown3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Segment\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dates\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"reviewID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"reviewerID\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"productID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#create the target df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'LIWC_result' is not defined"]}]},{"cell_type":"markdown","source":["**TODO:** Create a NLP Model that will take in our vector of each review's category and createa  "],"metadata":{"id":"3zuqzvwJfv9b"}},{"cell_type":"code","source":["#read liwc results in as df\n","import pandas as pd\n","LIWC_result=pd.read_csv(\"LIWC-outputOnContentsAndNY.csv\");"],"metadata":{"id":"my8AdyAOQyIN","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"error","timestamp":1650573889679,"user_tz":240,"elapsed":247,"user":{"displayName":"Yifan She","userId":"10901471948661696856"}},"outputId":"33f49a9f-c3fb-4ee5-bf66-55c04c5d8e1b"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d26b06c5d092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#read liwc results in as df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLIWC_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LIWC-outputOnContentsAndNY.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LIWC-outputOnContentsAndNY.csv'"]}]},{"cell_type":"code","source":["\n","#This week HW 4/4/22:\n","\n","#read LIWC documentation and reformat the data to fit the LIWC software\n","#load this data into LIWC and see the report, and maybe try and download this as data for our manipulation\n","#build a classifier on top of LIWC report\n","#LIWC has a commandline, we want a commandline tool to process the data and then Python can execute cmd line \n","#LIWC report as an offline file and read from this file. \n","\n","#REALLY try to use cmd line\n","#for each review have an array of each of the above\n","#numpy stack (multiple vectors into a big matrix)\n","#np.vstack or np.stack\n","\n","#start building classifier once you get all the report\n","\n","\n","#Sprint 10 HW:\n","# Find a classifier that can model the discreet data we now have\n","# Logistic regression would be a good starting point (data normalization technique (normalize the large and small values to a similar ))\n","# use sklearn package for data preprocessing\n","\n","#---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","# LIWC reads like IRIS dataset \n","# read LIWC csv into a dictionary\n","#df2.to_csv(r'ss_review.txt', header=None, index=None)\n","\n","\n","#generate a csv file from the results of the LIWC software report (LIWC already does this)\n","\n","\n","\n","\n"],"metadata":{"id":"Df3fYSJgnMPj"},"execution_count":null,"outputs":[]}],"metadata":{"interpreter":{"hash":"dfb355322ce57e99dba64d1cb11b2f8def6be26d05a1e48047f2a3e6439981c0"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}